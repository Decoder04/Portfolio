{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our approach\n",
    "---\n",
    "We have interviewed around 26 interviwees including doctors, surgeons, nurses and hospital leadership (CEOs and department heads)\n",
    "\n",
    "Here we will be analysing the interview transcripts we generated from all the interviews and try to answer questions pertaining to our scope of the project.\n",
    "\n",
    "For now, we are looking into the following questions:\n",
    "1. What are the top 30 talked words during the interview?\n",
    "2. What are the top 20 themes emerging?\n",
    "3. What are interviewees talking about role wise?\n",
    "4. What are interviewees talking about age wise? (data not available currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "file = open('Aggregated Data for Analysis.csv')\n",
    "reader = reader(file)\n",
    "jj = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 rows\n",
      "[['ï»¿Date', 'Time', 'Duration (min)', 'Interviewee', 'Interviewer', 'Observer', 'Role', 'Role Coding', 'Hospital', 'Verbatim', 'Theme', 'Aggregate dimensions', 'Rodrigos Theme', 'WX theme (if different from Rodrigo)', 'positive/neutral/negative', 'Rodrigos Aggregate'], ['23-11-2020', '11.30.00 AM', '43', 'Dr. Kamal', 'Wan Xin', 'Celine', 'CEO', 'Hospital Leadership', 'Gleneagles Medini', \"I think over the last six months we have diversified our supply chain vendors and we are very closely with the corporate side to identify vendors that will be able to meet our demand and expectation. At the earliest stage of this interview I mentioned to you about interdependence and this is where the hospitals within the country leverage off each other because prior to Covid 19 we have our own vendors and some independently source their different vendors so With this pandemic. All this has been collated and managed and observed at the group level because then you'll be able to leverage all those because then we will be looking at within hospitals negotiating as one. Prior to this, many of the hospitals will negotiate in their own. So post pandemic, we are negotiating as a group. We are looking more inwards into the country and identify more and more local vendors to provide that level of security should another pandemic happens.\", 'Negotiating with vendors as a group', 'Group procurement', '', '', '', ''], ['23-11-2020', '11.30.00 AM', '43', 'Dr. Kamal', 'Wan Xin', 'Celine', 'CEO', 'Hospital Leadership', 'Gleneagles Medini', \"So any of the hospitals would have their own suppliers, they would have their own process. I wouldn't say they were totally independent. It's just that post pandemic, the level of synergy and collaboration between the hospitals, the level of synergy and collaboration has grown. The level of growth is definitely more with the pandemic.\", 'Synergy as a group', 'Group procurement', '', '', '', ''], ['23-11-2020', '11.30.00 AM', '43', 'Dr. Kamal', 'Wan Xin', 'Celine', 'CEO', 'Hospital Leadership', 'Gleneagles Medini', \"it shouldn't be just public private but among the private hospitals also, there could be significant collaboration between the different entities even our competitors. I think, I think we need to look into healthcare as one entity, instead of being separated as Individual business models.\", 'Private hospitals partnership to collaborate more', 'Partnerships with policymakers, public and private hospitals', '', '', '', ''], ['23-11-2020', '11.30.00 AM', '43', 'Dr. Kamal', 'Wan Xin', 'Celine', 'CEO', 'Hospital Leadership', 'Gleneagles Medini', 'it goes to the policymakers. They need to be able to start getting all the stakeholders together or talk to each other on the same table, In fact if they were to call us. We will be more than happy to come along. And share with us where our gaps where our strengths and I think it is also time for nation building. So once you start mapping out What are the resources that we are lacking within the country. Then only we can start charting the way forward.', 'Policymakers to foster synergy from private-private partnership to ensure continuity', 'Partnerships with policymakers, public and private hospitals', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 rows')\n",
    "\n",
    "print(jj[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing header from the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header = jj[0]\n",
    "jj = jj[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header:\n",
      "\n",
      "['ï»¿Date', 'Time', 'Duration (min)', 'Interviewee', 'Interviewer', 'Observer', 'Role', 'Role Coding', 'Hospital', 'Verbatim', 'Theme', 'Aggregate dimensions', 'Rodrigos Theme', 'WX theme (if different from Rodrigo)', 'positive/neutral/negative', 'Rodrigos Aggregate']\n"
     ]
    }
   ],
   "source": [
    "print('Header:\\n')\n",
    "print(header)\n",
    "\n",
    "row_verbatim = 9\n",
    "row_theme = 10\n",
    "row_role = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 30 talked words during the interview?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows of verbatim:\n",
      "\n",
      "['I', 'think', 'over', 'the', 'last', 'six', 'months', 'we', 'have', 'diversified']\n",
      "\n",
      "Total no of words: 18618\n"
     ]
    }
   ],
   "source": [
    "all_verbatim = []\n",
    "\n",
    "for row in jj:\n",
    "    words = row[row_verbatim].split()\n",
    "    for word in words:\n",
    "        all_verbatim.append(word)\n",
    "\n",
    "print('10 rows of verbatim:\\n')\n",
    "print(all_verbatim[:10])\n",
    "print('\\nTotal no of words: {}'.format(len(all_verbatim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of stop words- most common words spoken in the English language\n",
    "stop_words = [\"yeah\",\"say\",\"it,\",\"term\",\"that.\",\"that's\",\"j&j\",\"long\",\"equipment\",\"\",\"yeah,\",\"like\",\"come\",\"just\",\"need\",\"don't\",\"it's\",\"know\",\"know,\",\"it.\",\"i'm\",\"use\",\"lot\",\"doing\",\"actually\",\"things\",\"going\",\"really\",\"so,\",\"certain\",\"maybe\",\"thing\",\"there's\",\"way\",\"i\",\"think\",\"months\",\"identify\",\"at\",\"earliest\",\"prior\",\"with\",\"source\",\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to return a frequency table dictionary\n",
    "def find_freq(list_of_words):\n",
    "    freq_table = {}\n",
    "    for word in list_of_words:\n",
    "        cleaned_word = word.lower().replace(',','').replace('.','').replace('(','').replace(')','')\n",
    "        if cleaned_word not in stop_words:\n",
    "            if cleaned_word in freq_table:\n",
    "                freq_table[cleaned_word] += 1\n",
    "            else:\n",
    "                freq_table[cleaned_word] = 1\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each word excluding the stop words\n",
    "verbatim_freq = find_freq(all_verbatim)\n",
    "\n",
    "# Converting frequency table into array\n",
    "verbatims = []\n",
    "for key in verbatim_freq:\n",
    "    verbatims.append([verbatim_freq[key], key])\n",
    "    \n",
    "# Sorting the frequency array\n",
    "verbatims = sorted(verbatims, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_words_freq(list_words, number, role):\n",
    "    out_template = \"{word} has been spoken {count} times\"\n",
    "    print('Top {num} words spoken by {whom}:\\n'.format(num=number, whom=role))\n",
    "    for i in range(number):\n",
    "        print(out_template.format(word=list_words[i][1], count=list_words[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 30 words spoken by our interviewees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 words spoken by interviewees:\n",
      "\n",
      "products has been spoken 63 times\n",
      "hospital has been spoken 62 times\n",
      "time has been spoken 60 times\n",
      "product has been spoken 52 times\n",
      "new has been spoken 52 times\n",
      "good has been spoken 51 times\n",
      "people has been spoken 47 times\n",
      "zoom has been spoken 44 times\n",
      "want has been spoken 43 times\n",
      "covid has been spoken 43 times\n",
      "virtual has been spoken 39 times\n",
      "training has been spoken 38 times\n",
      "online has been spoken 31 times\n",
      "meeting has been spoken 28 times\n",
      "vendors has been spoken 27 times\n",
      "person has been spoken 27 times\n",
      "interaction has been spoken 27 times\n",
      "physical has been spoken 26 times\n",
      "webinar has been spoken 25 times\n",
      "surgeons has been spoken 25 times\n",
      "supply has been spoken 25 times\n",
      "reps has been spoken 25 times\n",
      "patients has been spoken 25 times\n",
      "pandemic has been spoken 25 times\n",
      "different has been spoken 25 times\n",
      "course has been spoken 24 times\n",
      "right has been spoken 23 times\n",
      "face has been spoken 23 times\n",
      "example has been spoken 23 times\n",
      "communication has been spoken 22 times\n"
     ]
    }
   ],
   "source": [
    "display_words_freq(verbatims, 30, 'interviewees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the top 20 themes emerging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows of verbatim:\n",
      "\n",
      "['Negotiating', 'with', 'vendors', 'as', 'a', 'group', 'Synergy', 'as', 'a', 'group']\n",
      "\n",
      "Total no of theme words: 1767\n"
     ]
    }
   ],
   "source": [
    "all_themes = []\n",
    "\n",
    "for row in jj:\n",
    "    words = row[row_theme].split()\n",
    "    for word in words:\n",
    "        all_themes.append(word)\n",
    "\n",
    "print('10 rows of verbatim:\\n')\n",
    "print(all_themes[:10])\n",
    "print('\\nTotal no of theme words: {}'.format(len(all_themes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the frequency of each word excluding the stop words\n",
    "theme_freq = find_freq(all_themes)\n",
    "\n",
    "# Converting frequency table into array\n",
    "themes = []\n",
    "for key in theme_freq:\n",
    "    themes.append([theme_freq[key], key])\n",
    "    \n",
    "# Sorting the frequency array\n",
    "themes = sorted(themes, reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_themes_freq(number):\n",
    "    out_template = \"{theme} theme has appeared {count} times\"\n",
    "    print('Top {num} themes that appeared during interviews:\\n'.format(num=number))\n",
    "    for i in range(number):\n",
    "        print(out_template.format(theme=themes[i][1], count=themes[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 themes emerging during our interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 themes that appeared during interviews:\n",
      "\n",
      "virtual theme has appeared 68 times\n",
      "training theme has appeared 66 times\n",
      "online theme has appeared 30 times\n",
      "interaction theme has appeared 26 times\n",
      "communication theme has appeared 23 times\n",
      "engagement theme has appeared 22 times\n",
      "restriction theme has appeared 20 times\n",
      "reps theme has appeared 18 times\n",
      "new theme has appeared 18 times\n",
      "covid theme has appeared 16 times\n",
      "face theme has appeared 14 times\n",
      "people theme has appeared 11 times\n",
      "f2f theme has appeared 11 times\n",
      "zoom theme has appeared 10 times\n",
      "service theme has appeared 10 times\n",
      "product theme has appeared 10 times\n",
      "idea theme has appeared 10 times\n",
      "future theme has appeared 10 times\n",
      "vendor theme has appeared 9 times\n",
      "supply theme has appeared 9 times\n"
     ]
    }
   ],
   "source": [
    "display_themes_freq(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are interviewees talking about role wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to filter out values and return filtered list\n",
    "def filter_list(filter):\n",
    "    jj_filter = []\n",
    "    for row in jj:\n",
    "        if row[row_role].lower() == filter:\n",
    "            jj_filter.append(row)\n",
    "    return jj_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering out roles\n",
    "\n",
    "jj_surgeon = filter_list('surgeon')\n",
    "jj_leadership = filter_list('hospital leadership')\n",
    "jj_nurse = filter_list('nurse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_words(list_words):\n",
    "    all_words = []\n",
    "\n",
    "    for row in list_words:\n",
    "        words = row[row_verbatim].split()\n",
    "        for word in words:\n",
    "            all_words.append(word)\n",
    "\n",
    "    # Finding the frequency of each word excluding the stop words\n",
    "    word_freq = find_freq(all_words)\n",
    "\n",
    "    # Converting frequency table into array\n",
    "    verbatims = []\n",
    "    for key in word_freq:\n",
    "        verbatims.append([word_freq[key], key])\n",
    "\n",
    "    # Sorting the frequency array\n",
    "    verbatims = sorted(verbatims, reverse = True)\n",
    "    return verbatims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 words spoken by surgeons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_common_words_surgeons = find_common_words(jj_surgeon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words spoken by surgeon:\n",
      "\n",
      "zoom has been spoken 40 times\n",
      "products has been spoken 40 times\n",
      "new has been spoken 38 times\n",
      "product has been spoken 33 times\n",
      "want has been spoken 32 times\n",
      "time has been spoken 30 times\n",
      "good has been spoken 28 times\n",
      "meeting has been spoken 25 times\n",
      "webinar has been spoken 24 times\n",
      "physical has been spoken 23 times\n",
      "covid has been spoken 23 times\n",
      "people has been spoken 22 times\n",
      "interaction has been spoken 21 times\n",
      "surgeons has been spoken 19 times\n",
      "face has been spoken 19 times\n",
      "virtual has been spoken 17 times\n",
      "surgeon has been spoken 17 times\n",
      "probably has been spoken 17 times\n",
      "online has been spoken 17 times\n",
      "course has been spoken 17 times\n"
     ]
    }
   ],
   "source": [
    "display_words_freq(sorted_common_words_surgeons, 20, 'surgeon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 words spoken by Nurses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_common_words_nurse = find_common_words(jj_nurse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words spoken by nurses:\n",
      "\n",
      "training has been spoken 25 times\n",
      "hospital has been spoken 24 times\n",
      "people has been spoken 19 times\n",
      "good has been spoken 16 times\n",
      "products has been spoken 15 times\n",
      "virtual has been spoken 14 times\n",
      "time has been spoken 14 times\n",
      "nurses has been spoken 14 times\n",
      "product has been spoken 13 times\n",
      "online has been spoken 13 times\n",
      "covid has been spoken 12 times\n",
      "theatre has been spoken 11 times\n",
      "education has been spoken 11 times\n",
      "operation has been spoken 10 times\n",
      "new has been spoken 10 times\n",
      "staff has been spoken 9 times\n",
      "vendors has been spoken 8 times\n",
      "reps has been spoken 8 times\n",
      "skill has been spoken 7 times\n",
      "programme has been spoken 7 times\n"
     ]
    }
   ],
   "source": [
    "display_words_freq(sorted_common_words_nurse, 20, 'nurses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 words spoken by Hospital Leadership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_common_words_leadership = find_common_words(jj_leadership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words spoken by the hospital leadership:\n",
      "\n",
      "hospital has been spoken 29 times\n",
      "supply has been spoken 25 times\n",
      "patients has been spoken 21 times\n",
      "vendors has been spoken 18 times\n",
      "pandemic has been spoken 17 times\n",
      "time has been spoken 16 times\n",
      "users has been spoken 14 times\n",
      "hospitals has been spoken 13 times\n",
      "able has been spoken 13 times\n",
      "business has been spoken 12 times\n",
      "country has been spoken 11 times\n",
      "chain has been spoken 11 times\n",
      "reps has been spoken 10 times\n",
      "ppe has been spoken 10 times\n",
      "item has been spoken 10 times\n",
      "terms has been spoken 9 times\n",
      "look has been spoken 9 times\n",
      "items has been spoken 9 times\n",
      "inaudible has been spoken 9 times\n",
      "different has been spoken 9 times\n"
     ]
    }
   ],
   "source": [
    "display_words_freq(sorted_common_words_leadership, 20, 'the hospital leadership')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding frequency of words spoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 rows of column verbatim:\n",
      "\n",
      "[\"I think over the last six months we have diversified our supply chain vendors and we are very closely with the corporate side to identify vendors that will be able to meet our demand and expectation. At the earliest stage of this interview I mentioned to you about interdependence and this is where the hospitals within the country leverage off each other because prior to Covid 19 we have our own vendors and some independently source their different vendors so With this pandemic. All this has been collated and managed and observed at the group level because then you'll be able to leverage all those because then we will be looking at within hospitals negotiating as one. Prior to this, many of the hospitals will negotiate in their own. So post pandemic, we are negotiating as a group. We are looking more inwards into the country and identify more and more local vendors to provide that level of security should another pandemic happens.\", \"So any of the hospitals would have their own suppliers, they would have their own process. I wouldn't say they were totally independent. It's just that post pandemic, the level of synergy and collaboration between the hospitals, the level of synergy and collaboration has grown. The level of growth is definitely more with the pandemic.\", \"it shouldn't be just public private but among the private hospitals also, there could be significant collaboration between the different entities even our competitors. I think, I think we need to look into healthcare as one entity, instead of being separated as Individual business models.\", 'it goes to the policymakers. They need to be able to start getting all the stakeholders together or talk to each other on the same table, In fact if they were to call us. We will be more than happy to come along. And share with us where our gaps where our strengths and I think it is also time for nation building. So once you start mapping out What are the resources that we are lacking within the country. Then only we can start charting the way forward.', \"Very important. Medical supply. They form the foundation to our business. Without them we can't do what we do, no matter how good the doctors are or how well the business operates without our partners. So the a good supply chain, it will disrupt the care that we should deliver to our patients. It is actually the one of the very foundation that we need to get right.\"]\n"
     ]
    }
   ],
   "source": [
    "column_verbatim = []\n",
    "\n",
    "for row in jj:\n",
    "    column_verbatim.append(row[row_verbatim])\n",
    "\n",
    "        \n",
    "print('5 rows of column verbatim:\\n')\n",
    "print(column_verbatim[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_freq_words(array, word):\n",
    "    count = 0\n",
    "    for words in array:\n",
    "        if word in words:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "count = find_freq_words(column_verbatim, 'networking')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = find_freq_words(column_verbatim, 'nothing change')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "count = find_freq_words(column_verbatim, 'wait')\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
